---
title:  'SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution'  #  Paper title, covered by ''
teser: SEAL.png
type:   paper
pro_type: Image Super-Resolution
layout: post  #  Do not change this
date:   2023-02-07 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Wenlong Zhang, Xiaohui Li, Xiangyu Chen, Yu Qiao, Xiao-Ming Wu, Chao Dong # authors information
venue:  International Conference on Learning Representations (ICLR spotlight), 2024 #Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2024  # paper year, number
month:  January # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: https://github.com/XPixelGroup/SEAL  # If has data, post code link here, otherwise None
paperLink: https://www.semanticscholar.org/paper/SEAL%3A-A-Framework-for-Systematic-Evaluation-of-Zhang-Li/7cd9c39820d9d913dfc4e5066d655435984ace42 # post paper pdf link here
---

Real-world Super-Resolution (real-SR) methods focus on dealing with diverse real-world images and have attracted increasing attention in recent years. The key idea is to use a complex and high-order degradation model to mimic real-world degradations. Although they have achieved impressive results in various scenarios, they are faced with the obstacle of evaluation. Currently, these methods are only assessed by their average performance on a small set of degradation cases randomly selected from a large space, which fails to provide a comprehensive understanding of their overall performance and often yields biased results. To overcome the limitation in evaluation, we propose SEAL, a framework for systematic evaluation of real-SR. In particular, we cluster the extensive degradation space to create a set of representative degradation cases, which serves as a comprehensive test set. Next, we propose a coarse-to-fine evaluation protocol to measure the distributed and relative performance of real-SR methods on the test set. The protocol incorporates two new metrics: acceptance rate (AR) and relative performance ratio (RPR), derived from an acceptance line and an excellence line. Under SEAL, we benchmark existing real-SR methods, obtain new observations and insights into their performance, and develop a new strong baseline. We consider SEAL as the first step towards creating an unbiased and comprehensive evaluation platform, which can promote the development of real-SR.