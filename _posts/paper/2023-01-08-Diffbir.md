---
title:  'DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior'  #  Paper title, covered by ''
teser: Diffbir.png
type:   paper
pro_type: Image Super-Resolution
layout: post  #  Do not change this
date:   2023-01-08 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Xinqi Lin, Jingwen He, Ziyan Chen, Zhaoyang Lyu, Ben Fei, Bo Dai, Wanli Ouyang, Yu Qiao, Chao Dong # authors information
venue:  ArXiv, 2023 #Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2023  # paper year, number
month:  Sep # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: https://github.com/XPixelGroup/DiffBIR  # If has data, post code link here, otherwise None
paperLink: https://arxiv.org/abs/2308.15070 # post paper pdf link here
---

We present DiffBIR, which leverages pretrained text-to-image diffusion models for blind image restoration problem. Our framework adopts a two-stage pipeline. In the first stage, we pretrain a restoration module across diversified degradations to improve generalization capability in real-world scenarios. The second stage leverages the generative ability of latent diffusion models, to achieve realistic image restoration. Specifically, we introduce an injective modulation sub-network -- LAControlNet for finetuning, while the pre-trained Stable Diffusion is to maintain its generative ability. Finally, we introduce a controllable module that allows users to balance quality and fidelity by introducing the latent image guidance in the denoising process during inference. Extensive experiments have demonstrated its superiority over state-of-the-art approaches for both blind image super-resolution and blind face restoration tasks on synthetic and real-world datasets. 