---
title:  'DegAE: A New Pretraining Paradigm for Low-level Vision'  #  Paper title, covered by ''
teser: DegAE.png
type:   paper
pro_type: Image Super-Resolution
layout: post  #  Do not change this
date:   2022-10-20 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Yihao Liu, Jingwen He, Jinjin Gu, Xiangtao Kong, Yu Qiao, Chao Dong # authors information
venue:  Computer Vision and Pattern Recognition (CVPR highlight), 2023 #Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2023  # paper year, number
month:  March # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: None  # If has data, post code link here, otherwise None
paperLink: None # post paper pdf link here
---

Self-supervised pretraining has achieved remarkable success in high-level vision, but its application in low-level
vision remains ambiguous and not well-established. What is the primitive intention of pretraining? What is the core
problem of pretraining in low-level vision? In this paper,
we aim to answer these essential questions and establish
a new pretraining scheme for low-level vision. Specifically,
we examine previous pretraining methods in both high-level
and low-level vision, and categorize current low-level vision
tasks into two groups based on the difficulty of data acquisition: low-cost and high-cost tasks. Existing literature has
mainly focused on pretraining for low-cost tasks, where the
observed performance improvement is often limited. However, we argue that pretraining is more significant for highcost tasks, where data acquisition is more challenging. To
learn a general low-level vision representation that can improve the performance of various tasks, we propose a new
pretraining paradigm called degradation autoencoder (DegAE). DegAE follows the philosophy of designing pretext
task for self-supervised pretraining and is elaborately tailored to low-level vision. With DegAE pretraining, SwinIR
achieves a 6.88dB performance gain on image dehaze task,
while Uformer obtains 3.22dB and 0.54dB improvement on
dehaze and derain tasks, respectively.