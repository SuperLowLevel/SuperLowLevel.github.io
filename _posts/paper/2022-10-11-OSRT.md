---
title:  'OSRT: Omnidirectional Image Super-Resolution with Distortion-aware Transformer'  #  Paper title, covered by ''
teser: OSRT.png
type:  paper
pro_type: Omnidirectional Image Super-Resolution
layout: post  #  Do not change this
date:   2022-10-11 11:59:59 +0800  # paper pub data, only change year and month according to this format
author: Fanghua Yu, Xintao Wang, Mingdeng Cao, Gen Li, Ying Shan, Chao Dong
venue:  Computer Vision and Pattern Recognition (CVPR), 2023 #Where it be, ICCV and CVPR remove IEEE Conference on,
year:   2023  # paper year, number
month:  March # paper month, full name
projectPage: None  # If has project page, link here, otherwise None
supplemental : None
data: None  # If has data, post data link here, otherwise None
code: None   # If has data, post code link here, otherwise None
paperLink: https://arxiv.org/abs/2302.03453 # post paper pdf link here
---
Omnidirectional images (ODIs) have obtained lots of research interest for immersive experiences. Although ODIs
require extremely high resolution to capture details of the
entire scene, the resolutions of most ODIs are insufficient.
Previous methods attempt to solve this issue by image
super-resolution (SR) on equirectangular projection (ERP)
images. However, they omit geometric properties of ERP in
the degradation process, and their models can hardly generalize to real ERP images. In this paper, we propose Fisheye
downsampling, which mimics the real-world imaging process and synthesizes more realistic low-resolution samples.
Then we design a distortion-aware Transformer (OSRT) to
modulate ERP distortions continuously and self-adaptively.
Without a cumbersome process, OSRT outperforms previous methods by about 0.2dB on PSNR. Moreover, we propose a convenient data augmentation strategy, which synthesizes pseudo ERP images from plain images. This simple
strategy can alleviate the over-fitting problem of large networks and significantly boost the performance of ODISR.
Extensive experiments have demonstrated the state-of-theart performance of our OSRT.